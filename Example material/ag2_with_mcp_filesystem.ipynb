{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b04378-221f-45ce-a9cc-cb58467b919d",
   "metadata": {},
   "source": [
    "Authors: Licong Xu and Boris Bolliet (Cambridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ed7aaa-e6c9-42c4-bad6-b5c16176ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.sse import sse_client\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from autogen import LLMConfig\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from autogen.mcp import create_toolkit\n",
    "import json\n",
    "import anyio\n",
    "import asyncio\n",
    "\n",
    "# Only needed for Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from autogen.agentchat.group import (\n",
    "    AgentNameTarget,\n",
    "    AgentTarget,\n",
    "    AskUserTarget,\n",
    "    ContextExpression,\n",
    "    ContextStr,\n",
    "    ContextStrLLMCondition,\n",
    "    ContextVariables,\n",
    "    ExpressionAvailableCondition,\n",
    "    ExpressionContextCondition,\n",
    "    GroupChatConfig,\n",
    "    GroupChatTarget,\n",
    "    Handoffs,\n",
    "    NestedChatTarget,\n",
    "    OnCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    "    SpeakerSelectionResult,\n",
    "    StayTarget,\n",
    "    StringAvailableCondition,\n",
    "    StringContextCondition,\n",
    "    StringLLMCondition,\n",
    "    TerminateTarget,\n",
    ")\n",
    "\n",
    "from autogen.agentchat.group.patterns import (\n",
    "    DefaultPattern,\n",
    "    ManualPattern,\n",
    "    AutoPattern,\n",
    "    RandomPattern,\n",
    "    RoundRobinPattern,\n",
    ")\n",
    "\n",
    "\n",
    "from autogen import ConversableAgent, UpdateSystemMessage\n",
    "from autogen.agents.experimental import DocAgent\n",
    "import os\n",
    "import copy\n",
    "from typing import Any, Dict, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from autogen.agentchat import initiate_group_chat, a_initiate_group_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522f8e10-d797-42f1-a3c5-ff0473f82573",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_path = Path(\"mcp_filesystem.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d5d303-7256-4507-8c2f-6eff59e4085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joker_message = \"\"\"\n",
    "You are the joker in the team. You make jokes. \n",
    "\n",
    "You must obey the following constraints:\n",
    "\n",
    "{joke_constraints}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class JokeResponse(BaseModel):\n",
    "    joke_instructions: str = Field(..., description=\"instruction, not in the style of Shakespeare\")     \n",
    "    joke: str = Field(..., description=\"The joke. The joke must be in the style of Shakespeare\")\n",
    "    joke_explanation: str = Field(..., description=\"explanation, not in the style of Shakespeare\")\n",
    "    def format(self) -> str:\n",
    "        return \"\\n\".join([\n",
    "            \"**Joke instructions:**\",\n",
    "            \"\",\n",
    "            self.joke_instructions,\n",
    "            \"\",\n",
    "            \"**Joke:**\",\n",
    "            \"\",\n",
    "            self.joke,\n",
    "            \"\",\n",
    "            \"**Joke explanation:**\",\n",
    "            \"\",\n",
    "            self.joke_explanation\n",
    "        ])\n",
    "\n",
    "\n",
    "default_llm_config = {'cache_seed': 42,\n",
    "                     'temperature': 1.,\n",
    "                     'top_p': 0.05,\n",
    "                     'config_list': [{'model': 'gpt-4o',\n",
    "                                      'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "                                      'api_type': 'openai'}],\n",
    "                     'timeout': 1200}\n",
    "\n",
    "joker_config_list = copy.deepcopy(default_llm_config)\n",
    "joker_config_list['config_list'][0]['response_format'] = JokeResponse\n",
    "\n",
    "\n",
    "joker =  ConversableAgent(\n",
    "    name=\"joker\",\n",
    "    system_message=joker_message,\n",
    "    # llm_config=LLMConfig(model=\"gpt-4o\", \n",
    "    #                      api_type=\"openai\",\n",
    "    #                      response_format=JokeResponse\n",
    "    #                     ),\n",
    "    llm_config = joker_config_list,\n",
    "    update_agent_state_before_reply=[UpdateSystemMessage(joker_message),],\n",
    ")\n",
    "\n",
    "workflow_context = ContextVariables(data={\n",
    "    \"joke_constraints\": \"the joke should make use of the contextual information passed on to you. It should be a paragraph long and use as much detailed information from the context as possible.\",\n",
    "})\n",
    "\n",
    "\n",
    "task = \"\"\"\n",
    "Read the file in context and Make a joke.\n",
    "\"\"\"\n",
    "\n",
    "initial_agent = joker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1baf8175-01ce-48bf-b9f3-1f6bfcaa0b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all agents reset\n",
      ".cache folder deleted.\n",
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Read the file in context and Make a joke.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_UvDvl8QM4Mc9GDpdM61Bq4hL): list_files *****\u001b[0m\n",
      "Arguments: \n",
      "{\"relative_path\":\"context\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION list_files...\n",
      "Call ID: call_UvDvl8QM4Mc9GDpdM61Bq4hL\n",
      "Input arguments: {'relative_path': 'context'}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_UvDvl8QM4Mc9GDpdM61Bq4hL) *****\u001b[0m\n",
      "('Not a directory: context', None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_qLnUojpYUtEw2cLykO9gh3N4): list_files *****\u001b[0m\n",
      "Arguments: \n",
      "{\"relative_path\":\"context_docs\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION list_files...\n",
      "Call ID: call_qLnUojpYUtEw2cLykO9gh3N4\n",
      "Input arguments: {'relative_path': 'context_docs'}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_qLnUojpYUtEw2cLykO9gh3N4) *****\u001b[0m\n",
      "(['.DS_Store', 'eiffel_tower.md', '.ipynb_checkpoints'], None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_EXZmb1J32ifDQrGeXjzX5PX2): read_file *****\u001b[0m\n",
      "Arguments: \n",
      "{\"relative_path\":\"context_docs/eiffel_tower.md\"}\n",
      "\u001b[32m**************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION read_file...\n",
      "Call ID: call_EXZmb1J32ifDQrGeXjzX5PX2\n",
      "Input arguments: {'relative_path': 'context_docs/eiffel_tower.md'}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_EXZmb1J32ifDQrGeXjzX5PX2) *****\u001b[0m\n",
      "('Rising above the left bank of the\\u202fRiver\\u202fSeine, the Eiffel\\u202fTower is both a product of late‑19th‑century engineering daring and a symbol of modern Paris.\\n\\n### Conception and Construction (1886\\u202f–\\u202f1889)\\n\\n* **Origins:** Paris needed a spectacular centerpiece for the 1889 *Exposition\\u202fUniverselle*, held to mark the centennial of the French Revolution. The government announced an open competition for a 300‑meter iron tower to be erected on the Champ‑de‑Mars, the broad field that slopes gently toward the Seine.\\n* **Gustave Eiffel’s design:** Engineer Gustave Eiffel and collaborators Maurice Koechlin, Émile Nouguier (structural), and architect Stephen Sauvestre submitted the winning proposal. Their plan combined wrought‑iron lattices—light yet incredibly strong—curving inwards to reduce wind loads while framing dramatic views of the nearby river.\\n* **Building the giant:** Foundations were sunk in January\\u202f1887 only a few dozen meters from the Seine’s embankment. Prefabricated iron pieces—18,038 of them—were riveted together like an enormous Meccano set. Two years, two months, and five days later, on 31\\u202fMarch\\u202f1889, Eiffel ascended the tower’s top to plant the French flag.\\n\\n### Early Reputation and Uses (1889\\u202f–\\u202f1914)\\n\\n* **Mixed reception:** Many artists and writers decried it as a “metal asparagus,” but fairgoers loved the panoramic view over Paris and its sinuous river. In its first year the tower drew almost two million visitors, proving its commercial worth.\\n* **Scientific platform:** Eiffel championed practical uses to prevent demolition after the exposition’s 20‑year lease. Meteorological and aerodynamic experiments began almost immediately; by 1903 the tower hosted one of the world’s first public radio transmitters, exploiting its height above the Seine basin for clear signals.\\n\\n### World Wars and Modernization (1914\\u202f–\\u202f1960s)\\n\\n* **Strategic mast:** During World\\u202fWar\\u202fI, wireless equipment on the tower jammed German communications and relayed orders to the front.\\n* **Aviation beacon:** Between the wars the tower’s red‑and‑white rotating beacon became a nighttime guide for pilots following the Seine corridor into Paris.\\n* **Post‑war renewal:** In 1957 a 24‑meter television antenna lifted the structure’s total height to 324\\u202fm (1,063\\u202fft). The elevators—originally hydraulic and powered by water pumped from the Seine—were gradually electrified and modernized.\\n\\n### The Late‑20th Century to Today\\n\\n* **Preservation efforts:** Extensive repainting (every seven years) guards against corrosion from the river’s humid breezes. Major refurbishments for the tower’s centenary (1989) and the millennium improved visitor flow, while a 2013 glass‑floor section on the first level lets guests look straight down to the esplanade bordering the Seine.\\n* **Cultural icon:** Featured in countless films and illuminated nightly, the Eiffel\\u202fTower now hosts about seven million visitors each year. Its silhouette—mirrored in the Seine below—remains shorthand worldwide for Parisian elegance and French technological flair.\\n\\n### Quick Facts\\n\\n| Key Date | Milestone                                                             |\\n| -------- | --------------------------------------------------------------------- |\\n| 1889     | Official opening for the Exposition Universelle                       |\\n| 1909     | City of Paris decides to keep the tower (radio value)                 |\\n| 1914     | First military radio interception from the tower                      |\\n| 1957     | TV antenna installed; height becomes 324\\u202fm                            |\\n| 1986‑87  | Elevators and lighting overhauled                                     |\\n| 2024     | Latest repaint begins, still using the signature “Eiffel\\u202fTower brown” |\\n\\nFrom its footings at the Seine’s edge to the beacon that still sweeps the Paris sky, the Eiffel\\u202fTower embodies the industrial age’s optimism and the enduring romance of the river that flows beside it.\\n', None)\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmcp_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_2kJvj32iCPVBBuBbC4MudEdw): transfer_to_joker_1 *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION transfer_to_joker_1...\n",
      "Call ID: call_2kJvj32iCPVBBuBbC4MudEdw\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33m_Group_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_2kJvj32iCPVBBuBbC4MudEdw) *****\u001b[0m\n",
      "Transfer to joker\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoker\u001b[0m (to chat_manager):\n",
      "\n",
      "**Joke instructions:**\n",
      "\n",
      "Create a joke about the Eiffel Tower using the information from the file.\n",
      "\n",
      "**Joke:**\n",
      "\n",
      "Oh, fair Paris, where the Seine doth flow, and the Eiffel Tower doth stand, a marvel of iron and engineering grand! But hark, what jest is this? They say the artists of yore did call it a 'metal asparagus'! Aye, 'tis true, for in the garden of Paris, it doth rise like a vegetable most peculiar, yet none can deny its allure. Forsooth, when Gustave Eiffel did ascend to plant the flag, did he not think, 'To the top of this iron stalk, I shall climb, and from here, I shall see if the Seine doth indeed flow with wine!' Alas, 'tis but a jest, for the river flows with naught but water, and the tower stands as a beacon, guiding all who seek the heart of France.\n",
      "\n",
      "**Joke explanation:**\n",
      "\n",
      "The joke plays on the historical fact that some artists and writers initially criticized the Eiffel Tower by calling it a 'metal asparagus.' It humorously imagines Gustave Eiffel climbing the tower and jokingly hoping to see the Seine flowing with wine, which is a playful exaggeration of the romantic and whimsical view of Paris.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (9f9ec6b5-4b8e-4187-a981-40f9a7c16921): No next speaker selected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def create_toolkit_and_run(session: ClientSession) -> None:\n",
    "    # Create a toolkit with available MCP tools\n",
    "    toolkit = await create_toolkit(session=session)\n",
    "    mcp_agent = ConversableAgent(name=\"mcp_agent\", \n",
    "                             system_message=r\"\"\"\n",
    "Read the file in your folder. \n",
    "                             \"\"\",\n",
    "                             llm_config=LLMConfig(model=\"gpt-4o\", \n",
    "                                                  api_type=\"openai\",\n",
    "                                                  tool_choice=\"required\"\n",
    "                                                 ))\n",
    "    # Register MCP tools with the agent\n",
    "    toolkit.register_for_llm(mcp_agent)\n",
    "    \n",
    "    toolkit.register_for_execution(mcp_agent)\n",
    "\n",
    "    # joker.handoffs.set_after_work(AgentTarget(mcp_agent))\n",
    "    joker.handoffs.set_after_work(TerminateTarget())\n",
    "    \n",
    "    mcp_agent.handoffs.set_after_work(AgentTarget(joker))\n",
    "\n",
    "\n",
    "    mcp_agent.handoffs.add_llm_conditions([\n",
    "            OnCondition(\n",
    "                target=AgentTarget(joker),\n",
    "                condition=StringLLMCondition(prompt=\"The file has been read.\"),\n",
    "                # available=StringAvailableCondition(context_variable=\"requires_login\"),\n",
    "            ),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    agents=[joker,\n",
    "            mcp_agent,\n",
    "               ]\n",
    "    \n",
    "    for agent in agents:\n",
    "        agent.reset()\n",
    "    print(\"all agents reset\")\n",
    "\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    def delete_cache_folder():\n",
    "        cache_path = os.path.join(os.getcwd(), \".cache\")\n",
    "        if os.path.isdir(cache_path):\n",
    "            shutil.rmtree(cache_path)\n",
    "            print(\".cache folder deleted.\")\n",
    "        else:\n",
    "            print(\"No .cache folder found in current directory.\")\n",
    "    \n",
    "    delete_cache_folder()\n",
    "\n",
    "    # Create the pattern\n",
    "    agent_pattern = DefaultPattern(\n",
    "      agents=[joker, mcp_agent],\n",
    "      initial_agent=mcp_agent,\n",
    "      context_variables=workflow_context,\n",
    "    )\n",
    "    \n",
    "\n",
    "    await a_initiate_group_chat(\n",
    "            pattern=agent_pattern,\n",
    "            messages=task,\n",
    "            max_rounds=20,\n",
    "        )\n",
    "\n",
    "\n",
    "# Create server parameters for stdio connection\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",  # The command to run the server\n",
    "    args=[\n",
    "        str(mcp_server_path),\n",
    "        \"stdio\",\n",
    "    ],  # Path to server script and transport mode\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write), ClientSession(read, write) as session:\n",
    "    # Initialize the connection\n",
    "    await session.initialize()\n",
    "    await create_toolkit_and_run(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722f618-d54b-4d0f-9314-5ccfa5748d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env",
   "language": "python",
   "name": "mcp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
